{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06df1c6a-4286-4fe2-9a1a-b43b7d8a511b",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93ad9c-84bc-4b9c-85eb-91bed09fcada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b152e5f-a9ca-4140-b01c-d50cbe36a1eb",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecdc05-cfcf-404c-82ee-0829151d01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076bb65e-186a-45ae-b9ce-71fe250defbd",
   "metadata": {},
   "source": [
    "I decided to proceed with TPOT as an AutoML framework. Initially, I was considering auto-sklearn, but after reading this article where TPOT was recommended for regression problems (https://medium.com/georgian-impact-blog/choosing-the-best-automl-framework-4f2a90cb1826), I made my choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1643f9-1d3f-4bf4-8aa7-19bbdec3337b",
   "metadata": {},
   "source": [
    "Now let's split this dataframe into train and test. We'll pick the last 5 days as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6629e-4b7c-4adf-8ae4-46aee86f3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique dates that correspond to 20% of the dataset\n",
    "num_dates = int(df['date'].nunique() * 0.2)\n",
    "\n",
    "# Get the date that splits the data into 80% training and 20% testing\n",
    "split_date = df['date'].unique()[-num_dates]\n",
    "\n",
    "# Splitting the dataset\n",
    "train = df[df['date'] < split_date]\n",
    "test = df[df['date'] >= split_date]\n",
    "\n",
    "X_train = train.drop(columns=['pageviews_-1d_lag', 'offer_id', 'date'])  # Dropping 'date' as it's not a feature\n",
    "y_train = train['pageviews_-1d_lag']\n",
    "\n",
    "X_test = test.drop(columns=['pageviews_-1d_lag', 'offer_id', 'date'])\n",
    "y_test = test['pageviews_-1d_lag']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec907bcd-34ec-4310-a080-bd828687813f",
   "metadata": {},
   "source": [
    "Define searching space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7a40c-ede0-4672-9046-684184c1fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_config = {\n",
    "    # Existing ensemble models\n",
    "    'sklearn.ensemble.RandomForestRegressor': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "        'max_depth': [1, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10, 15, 20],\n",
    "        'min_samples_leaf': [1, 5, 10, 15, 20],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'xgboost.XGBRegressor': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [1, 5, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [1, 2, 5, 10]\n",
    "    },\n",
    "    'lightgbm.LGBMRegressor': {\n",
    "        'num_leaves': [20, 50, 100, 150],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [1, 5, 10]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c86371-8fa2-471f-8175-690a6c3fe5a7",
   "metadata": {},
   "source": [
    "### Instantiate the TPOTRegressor for AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedebcb9-1f00-48da-bba2-b6299647a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "# Create a TimeSeriesSplit object\n",
    "time_series_cv = TimeSeriesSplit(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712cf399-8085-45a9-85e4-6fdcbcb7360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTRegressor(\n",
    "    generations=5,\n",
    "    population_size=50,\n",
    "    n_jobs=-1,\n",
    "    verbosity=2, \n",
    "    cv=time_series_cv,\n",
    "    random_state=42,\n",
    "    max_time_mins=60,\n",
    "    max_eval_time_mins=10,\n",
    "    config_dict=tpot_config,\n",
    ")\n",
    "\n",
    "# Run TPOT\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a338b34-668a-41ff-9cb1-c89813acd236",
   "metadata": {},
   "source": [
    "Run the TPOT optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd2422-553e-4f9f-ab8e-f62dcd9aaee2",
   "metadata": {},
   "source": [
    "Check the score of the best pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c7f66-99ae-4bf6-ac28-71cd15baef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Score: \", tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7316604-a97e-4ba7-9c28-7f3de78ec469",
   "metadata": {},
   "source": [
    "Export the best pipeline as a Python script file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b097b-b172-422a-99b3-707dbab75263",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_model_selection/tpot_model_pipeline_ensemble.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6d52c-2089-430b-ab29-2b7b1184debf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
